# Machine-Learning-
---
title: "Machine Learning Project"
output: html_document
---
### **Project**
####  In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. 
### **Project by Olivia**
#### 1. Introduction to dataset ( training and testing )
##### step1: Import Training Data 
```{r,echo=T}
setwd('/Users/apple/Desktop/Cousera/Data Science/4.Machine Learning JHopkins')
f1=download.file('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv',
                 destfile = '/Users/apple/Desktop/Cousera/Data Science/4.Machine Learning JHopkins/train.csv',method='curl')
train=read.csv('train.csv',na.strings=c("NA","#DIV/0!", ""))
dim(train)
```
##### Our Training dataset has 19622 observations and 160 features.
##### step2: Import Testing Data
```{r,echo=T}
f2=download.file('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv',
                 destfile = '/Users/apple/Desktop/Cousera/Data Science/4.Machine Learning JHopkins/test.csv',method='curl')
test=read.csv('test.csv',na.strings=c("NA","#DIV/0!", ""))
dim(test)
```
##### Our Testing dataset has 20 observations and 160 features.
##### step3: Know about our classification variable- 'classe'
##### The variable “classe” contains 5 levels: A, B, C, D and E. 
##### The following histogram show you the distribution of 'classe'. 
```{r,echo=T}
library(ggplot2)
g1=ggplot(train, aes(classe,fill=classe))+geom_histogram(binwidth=1)
g1=g1+xlab("Classe Levels for Training ")+ylab("Frequency Training ");g1
```
##### step4: Preprocessing our features( shrinking the number of features to 53 )
##### Before our classification analysis, we should make clear 2 points:
##### (1) Are the features in training set are the same with testing set? If not, which features are not the same?
```{r,echo=T}
all.equal(colnames(train),colnames(test))
(colnames(train))[which(colnames(train)!=colnames(test))]
(colnames(test))[which(colnames(train)!=colnames(test))]
```
##### (2) Which featrues are correlated to 'Classe'? 
##### As known, there are 159 feartures in our datasets and one Dependent variable-'Classe'. The features are too many to make a reasonable and efficient classification for 'Classe'.Thus we should delete irrelavant features first.
##### First, I delete the first 7 columns, they are relavant to the 'Classe'
```{r,echo=T}
train=train[,-c(1:7)]
test =test[,-c(1:7)]
```
##### Second, Delete columns with all missing values.
##### 
```{r,echo=T}
train<-train[,colSums(is.na(train)) == 0]
test <-test[,colSums(is.na(test)) == 0]
all.equal(colnames(train),colnames(test))
dim(train);dim(test)
```
##### \(^_^)/ Now, there are 53 features in both our training set and testing test. And we should find reasonable and efficient ways in training set to classify the 'Classe' and then utilize this method to label the testing set, which has no 'classe' feature. 
##### Thus, in order to better classify the 'classe'with higher accuracy, we need partition the training test to subtrain test and subtest set. Then both sets have 'classe' feature, we can make comparison according to model accuracy among different models.
##### step5 : Partition the training set
##### Considering that there is no 'classe' feature in test set, we should assign more data to subtest set, which can provide more reliable validation on prediction.
##### In order to perform cross validation,  we set the subtrain set ( 60 % ) and subtest ( 40% ) 
```{r,echo=T}
library(caret)
sub <- createDataPartition(y=train$classe, p=0.6, list=FALSE)
subTrain <- train[sub, ] 
subTest <- train[-sub, ]
dim(subTrain)
dim(subTest)
```
##### After partitioning our training set, now both subtrain and subtest sets have the 'classe' feature. Another question is : Whether 'classe' in both set has the same distribution? 
##### The left one shows you 'classe' in subtrain and the right one is in subtest. The follwing 2 graphs show us the weight among A,B,C,D,E is around the same in both subtrain and subtest.
##### Thus it is relible that we validate our classification model(buillt by subtrain) ,on subtest set.
```{r,echo=T}
library(ggplot2);library(gridExtra)
g1=ggplot(subTrain, aes(classe,fill=classe))+geom_histogram(binwidth=1)
g1=g1+xlab("Classe Levels for Subtrain ")+ylab("Frequency Subtrain ");g1
g2=ggplot(subTest, aes(classe,fill=classe))+geom_histogram(binwidth=1)
g2=g2+xlab("Classe Levels for Subtest ")+ylab("Frequency Subtest");g2
grid.arrange(g1,g2,ncol=2)
```

#### 2. Classification model
##### step1. Predictin with Trees
```{r,echo=T}
mTree=train(classe~., data=subTrain,method='rpart')
library(rpart.plot)
library(rattle)
fancyRpartPlot(mTree$finalModel)
AcuraTrain=confusionMatrix(predict(mTree,subTrain), subTrain$classe)$overall['Accuracy'] 
AcuraTrain       
AcuraTest=confusionMatrix(predict(mTree,subTest)  , subTest$classe)$overall['Accuracy']
AcuraTest        
pTree=predict(mTree,test)
```
##### step2. Predicting using Linear Discrimination
```{r,echo=T}
mLds=train(classe~., data=subTrain,method='lda',verbose=F)
AcuraTrain=confusionMatrix(predict(mLds,subTrain), subTrain$classe)$overall['Accuracy'] 
AcuraTrain          
AcuraTest=confusionMatrix(predict(mLds,subTest)  , subTest$classe)$overall['Accuracy']
AcuraTest           
pLds=predict(mLds,test)
```
##### step3. Unsupervised Prediction
##### Becase we know in advance that classe has 5 levels, thus after deleting the classe feature, we cluster all the features into 5 clusters.
```{r}
# 1. clustering our 52 features into 5 clusters.
#kMeans1 <- kmeans(subset(subTrain,select=-c(classe) ),centers=5   )
#subTrain$cluster <- as.factor(kMeans1$cluster)
# 2. Compare to real labels
#table(subTrain$cluster,subTrain$classe)
# 3. Build predictor
#modFit <- train(clusters ~.,data=subset(subTrain,select=-c(classe)),method="rpart")
#confusionMatrix(predict(modFit,subTrain),subTrain$classe)$overall['Accuracy']
# 4. Apply on subtest
#confusionMatrix(predict(modFit,subTest),subTest$classe)$overall['Accuracy']
# 5. Predict on test
#pCluster=predict(modFit,test)
```
##### Now, we know that the unsupervised learning is not suitable for every classification. 

##### step4. Ensembling all the 3 methods together
##### 1). Predict on the subtest set
##### pTree : prediction on subtest set using Tree Model.
##### pRf   : prediction on subtest set using Random Forest Model.
##### 2). Fit a model that combines predictors

```{r,echo=T}
pT=predict(mTree,subTest)
pL=predict(mLds,subTest)
predDF <- data.frame(pT,pL,y=subTest$classe)
model <- train(y ~.,method="rf",data=predDF)
Pred <- predict(model,predDF)
confusionMatrix(Pred,subTest$classe)$overall['Accuracy']       # Accuracy: 0.7204
pCombo=predict(model,test)
```

##### step5. [>_<]/My final classificaiton model
##### To sum up, the accuracy rates of 3 models as followings:
##### 1) For tree : Accuracy(subtrain)= 0.4947   ;
                    Accuracy(subtest) = 0.4960   
##### 2) For linear discrimination model:
                    Accuracy(subtrain)= 0.7053   ;
                    Accuracy(subtest) = 0.7064
##### 3) For tree & Linear combined model:
                    Accuracy(subtest)= 0.7204
##### The good thing is that the accuracy on subtest is better than that on subtrain. However, even the hightes accuracy on the combined model is not good enough, only at 72%.
##### Moreover, due to the weak prediction of tree model, i use the second and third model to make a prediction on test set. And the following are the result. And the left one is linear discrimination model and right one is combined model. 
```{r,echo=T}
library(ggplot2);library(gridExtra)
dat=data.frame(pLds,pCombo)
g2=ggplot(dat, aes(pLds,fill=pLds))+geom_histogram()
g2=g2+xlab("Classe Levels for Test ")+ylab("Frequency Test")+title("Prediction of LDS Model ");g2

g3=ggplot(dat, aes(pCombo,fill=pCombo))+geom_histogram()
g3=g3+xlab("Classe Levels for Test ")+ylab("Frequency Test")+title("Prediction of Combined Model ");g3
grid.arrange(g2,g3,ncol=2)
```








