---
title: "Machine Learning Project"
output: html_document
---
### **Project**
####  In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. 
### **Project by Olivia**
#### Part 1. Introduction to dataset ( training and testing )
##### step1: Import Training Data 
```{r,echo=T}
setwd('/Users/apple/Desktop/Cousera/Data Science/4.Machine Learning JHopkins')
f1=download.file('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv',
                 destfile = '/Users/apple/Desktop/Cousera/Data Science/4.Machine Learning JHopkins/train.csv',method='curl')
train=read.csv('train.csv',na.strings=c("NA","#DIV/0!", ""))
dim(train)
```
##### Our Training dataset has 19622 observations and 160 features.
##### step2: Import Testing Data
```{r,echo=T}
f2=download.file('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv',
                 destfile = '/Users/apple/Desktop/Cousera/Data Science/4.Machine Learning JHopkins/test.csv',method='curl')
test=read.csv('test.csv',na.strings=c("NA","#DIV/0!", ""))
dim(test)
```
##### Our Testing dataset has 20 observations and 160 features.
##### step3: Know about our classification variable- 'classe'
##### The variable “classe” contains 5 levels: A, B, C, D and E. 
##### The following histogram show you the distribution of 'classe'. 
```{r,echo=T}
library(ggplot2)
g1=ggplot(train, aes(classe,fill=classe))+geom_histogram(binwidth=1)
g1=g1+xlab("Classe Levels for Training ")+ylab("Frequency Training ");g1
```
##### step4: Preprocessing our features( shrinking the number of features to 53 )
##### Before our classification analysis, we should make clear 2 points:
##### (1) Are the features in training set are the same with testing set? If not, which features are not the same?
```{r,echo=T}
all.equal(colnames(train),colnames(test))
(colnames(train))[which(colnames(train)!=colnames(test))]
(colnames(test))[which(colnames(train)!=colnames(test))]
```
##### (2) Which featrues are correlated to 'Classe'? 
##### As known, there are 159 feartures in our datasets and one Dependent variable-'Classe'. The features are too many to make a reasonable and efficient classification for 'Classe'.Thus we should delete irrelavant features first.
##### First, I delete the first 7 columns, they are relavant to the 'Classe'
```{r,echo=T}
train=train[,-c(1:7)]
test =test[,-c(1:7)]
```
##### Second, Delete columns with all missing values.
```{r,echo=T}
train<-train[,colSums(is.na(train)) == 0]
test <-test[,colSums(is.na(test)) == 0]
all.equal(colnames(train),colnames(test))
dim(train);dim(test)
```
##### Third, Using PCA to reduce the colinearity among our 53 features.
```{r,echo=T}
which(colnames(train)=='classe')       # 53
which(colnames(test)=='problem_id')    # 53
library(caret)
PCA<- preProcess(train[,-53],method="pca")
TrainPca <- predict(PCA,train[,-53])
TrainPca$classe=train$classe        
dim(TrainPca)
TestPca <- predict(PCA,train[,-53])
dim(TestPca) 
# PCA needed 25 components to capture 95 percent of the variance
```
##### Now, I shrink 53 features in training set into 25 PCA and 1 response variables-'classe'.
##### step5 : Partition the training set
##### Considering that there is no 'classe' feature in test set, we should assign more data to subtest set, which can provide more reliable validation on prediction.
##### In order to perform cross validation,  I devided the training set as subtrain set ( 60 % ) and subtest ( 40% ).
4
```{r,echo=T}
library(caret)
sub <- createDataPartition(y=TrainPca$classe, p=0.6, list=FALSE)
subTrain <- TrainPca[sub, ] 
subTest <- TrainPca[-sub, ]
dim(subTrain)
dim(subTest)
head(subTrain,3)
```
##### After partitioning our training set, now both subtrain and subtest sets have the 'classe' feature. Another question is : Whether 'classe' in both set has the same distribution? 
##### The left one shows you 'classe' in subtrain and the right one is in subtest. The follwing 2 graphs show us the weight among A,B,C,D,E is around the same in both subtrain and subtest.
##### Thus it is relible that we validate our classification model(buillt by subtrain) ,on subtest set.
```{r,echo=T}
library(ggplot2);library(gridExtra)
g1=ggplot(subTrain, aes(classe,fill=classe))+geom_histogram(binwidth=1)
g1=g1+xlab("Classe Levels for Subtrain ")+ylab("Frequency Subtrain ")
g2=ggplot(subTest, aes(classe,fill=classe))+geom_histogram(binwidth=1)
g2=g2+xlab("Classe Levels for Subtest ")+ylab("Frequency Subtest")
grid.arrange(g1,g2,ncol=2)
```

#### Part 2. Classification with subtraining and subtesing 
##### step1. Predictin with Trees
```{r,echo=T}
mTree=train(classe~., data=subTrain,method='rpart')
library(rpart.plot)
library(rattle)
fancyRpartPlot(mTree$finalModel)
AcuraTrain=confusionMatrix(predict(mTree,subTrain), subTrain$classe)$overall['Accuracy'] 
AcuraTrain       
AcuraTest=confusionMatrix(predict(mTree,subTest)  , subTest$classe)$overall['Accuracy']
confusionMatrix(predict(mTree,subTest)  , subTest$classe)
AcuraTest        
```
##### After using PCA, The accuracy of tree is so bad!
##### How about we partition original training set without PCA, and still use tree classification.
```{r,echo=T}
library(caret)
control=trainControl(method = "cv", number = 7)
sub2 <- createDataPartition(y=train$classe, p=0.6, list=FALSE)
subTrain2 <- train[sub2, ] 
subTest2 <- train[-sub2, ]
dim(subTrain2)
dim(subTest2)
head(subTrain2,3)
mTree2=train(classe~., data=subTrain2,trControl=control,method='rpart')
library(rpart.plot)
library(rattle)
fancyRpartPlot(mTree2$finalModel)
AcuraTrain=confusionMatrix(predict(mTree2,subTrain2), subTrain2$classe)$overall['Accuracy'] 
AcuraTrain       
AcuraTest=confusionMatrix(predict(mTree2,subTest2)  , subTest2$classe)$overall['Accuracy']
confusionMatrix(predict(mTree2,subTest2)  , subTest2$classe)
```
##### To sum up, using Tree Classification for our trainingset, the accuracy is higher if we did not utilize PCA to our orginal training data.
##### Since Tree Classification did not provide me with the high accuracy, I use the Linear Discrimination Model to test.

##### step2. Predicting using Linear Discrimination
```{r,echo=T}
mLds=train(classe~., data=subTrain,method='lda',verbose=F)
AcuraTrain=confusionMatrix(predict(mLds,subTrain), subTrain$classe)$overall['Accuracy'] 
AcuraTrain          
AcuraTest=confusionMatrix(predict(mLds,subTest)  , subTest$classe)$overall['Accuracy']
AcuraTest           
confusionMatrix(predict(mLds,subTest)  , subTest$classe)
pLds=predict(mLds,TestPca)
```
##### The linear discrimination model still gets bad classification on dataset after PCA.The accuracy is only 50%.
##### How about we partition original training set without PCA, and still use tree classification.
```{r,echo=T}
library(caret)
sub2 <- createDataPartition(y=train$classe, p=0.6, list=FALSE)
subTrain2 <- train[sub2, ] 
subTest2 <- train[-sub2, ]
dim(subTrain2)
dim(subTest2)
head(subTrain2,3)
m2=train(classe~., data=subTrain2,method='lda')
AcuraTrain=confusionMatrix(predict(m2,subTrain2), subTrain2$classe)$overall['Accuracy'] 
AcuraTrain       
AcuraTest =confusionMatrix(predict(m2,subTest2) , subTest2$classe)$overall['Accuracy']
confusionMatrix(predict(m2,subTest2)  , subTest2$classe)
```
##### step3. Generalized Boosted Regression Models
##### From this step, I decided to use 7 folds cross-validation to my subtraining dataset. 
```{r,echo=T}
control=trainControl(method = "cv", number = 7)
```

```{r,echo=T}
library(gbm); library(survival)
mGbm=train(classe~., data=subTrain,method='gbm',trControl=control,verbose=F)
AcuraTrain=confusionMatrix(predict(mGbm,subTrain), subTrain$classe)$overall['Accuracy'] 
AcuraTrain          
AcuraTest=confusionMatrix(predict(mGbm,subTest)  , subTest$classe)$overall['Accuracy']
AcuraTest           
confusionMatrix(predict(mGbm,subTest),subTest$classe)
```
##### I am so happy >_< ! After using PCA to training set and use 7 fold cross validation, my General Boosting Model can predict the classe on subtest set with accuracy 82%. 
#####  How about GBM on training set without PCA?
```{r,echo=T}
dim(subTrain2); dim(subTest2)
m2=train(classe~., data=subTrain2,method='gbm',trControl=control,verbose=F)
AcuraTrain=confusionMatrix(predict(m2,subTrain2), subTrain2$classe)$overall['Accuracy'] 
AcuraTrain       
AcuraTest =confusionMatrix(predict(m2,subTest2) , subTest2$classe)$overall['Accuracy']
AcuraTest
```
##### Now, Gerneral Boosting Model on training set (without PCA) has prediction accuracy as 96% on both subtraining set and subtesting set. It is the best model I have.

##### Combined the Linear Discrimination,Tree Model and General Boosting Model, I can get 3 conclusions:
##### (1). The PCA did not help improve the accuracy of our prediction.
##### (2). For dataset without PCA, the rank among my models is : 
           GBM ( 96% ) > LDS ( 70% ) > Tree( 50% ).
           For dataset with PCA, the rank among my models is : 
           GBM ( 82% ) > LDS ( 53% ) > Tree( 38% ).
##### (3). Model selection can significantly improve the accuracy of prediction.
           General Boosting Model is the best model for this classification.
           
##### step4. [>_<]/My final classificaiton model: The GBM model without PCA.
##### The prediction built on GBM model and LDS model. 
```{r,echo=T}
pGbm=predict(m2,subTest2) 
library(ggplot2);library(gridExtra)
dat=data.frame(pGbm,y=subTest2$classe)
dat$true=(pGbm==subTest2$classe)
g1=ggplot(dat, aes(pGbm,fill=pGbm))+geom_histogram()
g1=g1+xlab("Classe Levels, GBM Model ")+ylab("Frequency GBM Model")
g2=ggplot(dat, aes(y,fill=y))+geom_histogram()
g2=g2+xlab("Classe Levels, subTest")+ylab("Frequency subTest")
grid.arrange(g1,g2,ncol=2)
qplot(dat$pGbm,fill=dat$true,alpha=0.4)+xlab('The prediction Value from GBM model')
```
#### Part 3. Prediction on test sets
##### This graph show you my classification for the 20 test points.
```{r,echo=T}
pred=predict(m2,test);pred
g=qplot(c(1:20),pred,col=as.factor(pred),size=15)
g=g+xlab('The serial number of test')+ ylab('The prediction result');
g
```

```{r}
library(markdown)
library(knitr)
result <- rpubsUpload(title='Machine',htmlFile='/Users/apple/Desktop/Cousera/Data Science/4.Machine Learning JHopkins/Machine.html',method=getOption('rpubs.upload.method','auto'))
result

```















